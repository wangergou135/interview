# network
mainly from InterviewGuide第四版By阿秀.pdf


## OSI 的七层模型
简要概括
物理层：底层数据传输，如网线；网卡标准。
数据链路层：定义数据的基本格式，如何传输，如何标识；如网卡MAC地址。
网络层：定义IP编址，定义路由功能；如不同设备的数据转发。
传输层：端到端传输数据的基本功能；如 TCP、UDP。
会话层：控制应用程序之间会话能力；如不同软件数据分发给不同软件。
表示层：数据格式标识，基本压缩加密功能。
应用层：各种应用软件，包括 Web 应用。

在四层，既传输层数据被称作段（Segments）；
三层网络层数据被称做包（Packages）；
二层数据链路层时数据被称为帧（Frames）；
一层物理层时数据被称为比特流（Bits）。

## 完整的HTTP请求过程
域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到
html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进
行渲染呈现给用户。

## DNS（Domain Name System，域名系统）
通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。


将主机域名转换为ip地址，属于应用层协议，使用UDP传输。

1. 为什么域名解析用UDP协议？
因为UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了

2. 为什么区域传送用TCP协议？
因为TCP协议可靠性好啊！
你要从主DNS上复制内容啊，你用不可靠的UDP？ 因为TCP协议传输的内容大啊，你用最大只能传512
字节的UDP协议？万一同步的数据大于512字节，你怎么办？所以用TCP协议比较好！

## HTTP长连接和短连接的区别
在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，
任务结束就中断连接。
而从HTTP/1.1起，默认使用长连接，用以保持连接特性

## 什么是TCP粘包/拆包？发生的原因？
一个完整的业务可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发
送，这个就是TCP的拆包和粘包问题。

1. 应用程序写入数据的字节大小大于套接字发送缓冲区的大小. 
2. 进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度) 
3. 以太网的payload大于MTU进行IP分片。（ MTU指：一种通信协议的某一层上面所能通过的最大数据
包大小。）

## 为什么服务器会缓存这一项功能?如何实现的？
原因
缓解服务器压力；
降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位
置上也有可能比源服务器来得近，例如浏览器缓存。
实现方法
让代理服务器进行缓存；
让客户端浏览器进行缓存。

## GET 和 POST 的区别
1. get是获取数据，post是修改数据
2. get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post
把数据放在HTTP的包体内（requrest body）
3. get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。
4. GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据); 
POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务
器响应200 ok(返回数据)。
5. GET请求会被浏览器主动缓存，而POST不会，除非手动设置。
6. 本质区别：GET是幂等的，而POST不是幂等的
这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着
对同一URL的多个请求应该返回同样的结果。
正因为它们有这样的区别，所以不应该且不能用get请求做数据的增删改这些有副作用的操作。因为get
请求是幂等的，在网络不好的隧道中会尝试重试。如果用get请求增数据，会有重复操作的风险，而这种
重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

## 一个TCP连接可以对应几个HTTP请求？
如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

## HTTPS和HTTP的区别
1. HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安
全， HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安
全。
2. https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
3. http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

## 什么是SSL/TLS
    SSL代表安全套接字层。它是一种用于加密和验证应用程序（如浏览器）和Web服务器之间发送的数据
的协议。 身份验证 ， 加密Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。
    SSL/TLS协议作用：认证用户和服务，加密数据，维护数据的完整性的应用层协议加密和解密需要两个
不同的密钥，故被称为非对称加密；
    加密和解密都使用同一个密钥的
对称加密：优点在于加密、解密效率通常比较高 ，
    HTTPS 是基于非对称加密的， 公钥是公开的，

## HTTPS是如何保证数据传输的安全，整体的流程是什么？（SSL是怎么工作保证安全的）
（1）客户端向服务器端发起SSL连接请求；
（2） 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥
（3）客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端
（4）服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密，
（5）进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，可以保证在
数据收发过程中的安全，即是第三方获得数据包，也无法对其进行加密，解密和篡改。
因为数字签名、摘要是证书防伪非常关键的武器。 “摘要”就是对传输的内容，通过hash算法计算出一段
固定长度的串。然后，通过发送方的私钥对这段摘要进行加密，加密后得到的结果就是“数字签名”
SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加
密信息，服务器收到密文后，用自己的私钥解密。

## 如何保证公钥不被篡改？
将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。
公钥加密计算量太大，如何减少耗用的时间？
每一次对话（session），客户端和服务器端都生成一个"对话密钥"（session key），用它来加密信息。由
于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减
少了加密运算的消耗时间。
（1） 客户端向服务器端索要并验证公钥。
（2） 双方协商生成"对话密钥"。 
（3） 双方采用"对话密钥"进行加密通信。上面过程的前两步，又称为"握手阶段"（handshake）。


## Cookie是什么

新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存
储）或 IndexedDB。
cookie 的出现是因为 HTTP 是无状态的一种协议，换句话说，服务器记不住你，可能你每刷新一次网
页，就要重新输入一次账号密码进行登录。这显然是让人无法接受的，cookie 的作用就好比服务器给你
贴个标签，然后你每次向服务器再发请求时，服务器就能够 cookie 认出你。


会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
个性化设置（如用户自定义设置、主题等）
浏览器行为跟踪（如跟踪分析用户行为等）

## Session知识大总结


除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服
务器端的信息更加安全。
Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数
据库中，效率会更高。
使用 Session 维护用户登录状态的过程如下：
1. 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
2. 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为
Session ID；
3. 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该
Cookie 值存入浏览器中；
4. 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从
Redis 中取出用户信息，继续之前的业务操作。
注意：Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜
到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如
转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密
码，或者使用短信验证码等方式。


## Cookie与Session的对比

1. Cookie
Cookie是客户端保持状态的方法。
Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。为了保持会话，服务
器可以在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户机收到Cookie之后保存这段字符
串，之后再请求时候带上Cookie就可以被识别。
除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是会话Cookie一种是持久
Cookie，会话Cookie就是将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁，持
久Cookie则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次
请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的Cookie是可以被多个浏览器代
理所共享的。
2. Session
Session是服务器保持状态的方法。
首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的
Session用户在客户端上记录用户的操作。我们可以理解为每个用户有一个独一无二的Session ID作为
Session文件的Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用
户操作行为。

3. 当服务器需要识别客户端时就需要结合Cookie了。每次HTTP请求的时候，客户端都会发送相应的Cookie
信息到服务端。实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服
务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID
发送到服务器，我就知道你是谁了。如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技
术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxxxx这样的参数，服务端
据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了。

## 什么是RARP

概括： 反向地址转换协议，网络层协议，RARP与ARP工作方式相反。 RARP使只知道自己硬件地址的
主机能够知道其IP地址。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所
需信息的RARP服务器发出的IP地址。
原理：
(1)网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网
卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的
IP地址。
(2)RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。
(3)PC1收到RARP回应后，就使用得到的IP地址进行通讯



## 端口有效范围
0-1023为知名端口号，比如其中HTTP是80，FTP是20（数据端口）、21（控制端口）
    UDP和TCP报头使用两个字节存放端口号，所以端口号的有效范围是从0到65535。动态端口的范围是从
1024到65535


## DNS查询方式有哪些
1. 递归解析
当局部DNS服务器自己不能回答客户机的DNS查询时，它就需要向其他DNS服务器进行查询。此时有两
种方式。局部DNS服务器自己负责向其他DNS服务器进行查询，一般是先向该域名的根域服务器查询，
再由根域名服务器一级级向下查询。最后得到的查询结果返回给局部DNS服务器，再由局部DNS服务器
返回给客户端。
2. 迭代解析
当局部DNS服务器自己不能回答客户机的DNS查询时，也可以通过迭代查询的方式进行解析。局部DNS
服务器不是自己向其他DNS服务器进行查询，而是把能解析该域名的其他DNS服务器的IP地址返回给客
户端DNS程序，客户端DNS程序再继续向这些DNS服务器进行查询，直到得到查询结果为止。也就是
说，迭代解析只是帮你找到相关的服务器而已，而不会帮你去查

## HTTP中缓存的私有和共有字段
    private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。
    Cache-Control: private

    public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。
    Cache-Control: public



## POST 方法会产生两个 TCP 数据包

POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送
body。
HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 
不会分开发送。
所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为



## Session和cookie应该如何去选择（适用场景）
    Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时
首选 Session；
    Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 
值进行加密，然后在服务器进行解密；
    对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有
的用户信息都存储到 Session 中


## Cookies和Session区别

Cookie和Session都是客户端与服务器之间保持状态的解决方案
1. 存储的位置不同，cookie：存放在客户端，session：存放在服务端。Session存储的数据比较安全
2. 存储的数据类型不同
两者都是key-value的结构，但针对value的类型是有差异的
cookie：value只能是字符串类型，session：value是Object类型
3. 存储的数据大小限制不同
cookie：大小受浏览器的限制，很多是是4K的大小， session：理论上受当前内存的限制，
4. 生命周期的控制
cookie的生命周期当浏览器关闭的时候，就消亡了
    (1)cookie的生命周期是累计的，从创建时，就开始计时，20分钟后，cookie生命周期结束，
    (2)session的生命周期是间隔的，从创建时，开始计时如在20分钟，没有访问session，那么session生命周期被销毁


## DDos 攻击

客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认
没有彻底根治的办法，除非不使用TCP
DDos 预防：
    1）限制同时打开SYN半链接的数目
    2）缩短SYN半链接的Time out 时间
    3）关闭不必要的服务

## MTU和MSS分别是什么

    MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。
    MSS：maximum segment size，最大分节大小，为TCP数据包每次传输的最大数据分段大小，一般由发送
端向对端TCP通知对端在每个分节中能发送的最大TCP数据。MSS值为MTU值减去IPv4 Header（20 
Byte）和TCP header（20 Byte）得到

## HTTP中有个缓存机制，但如何保证缓存是最新的呢？（缓存过期机制）

    max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。


    max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。


    Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。


    在 HTTP/1.1 中，会优先处理 max-age 指令；


    在 HTTP/1.0 中，max-age 指令会被忽略掉。

## TCP头部中有哪些信息

    序号（32bit）：传输方向上字节流的字节编号。初始时序号会被设置一个随机的初始值（ISN），之后每次发送数据时，序号值 = ISN + 数据在整个字节流中的偏移。假设A -> B且ISN = 1024，第一段数据512字节已经到B，则第二段数据发送时序号为1024 + 512。用于解决网络包乱序问题。ISN(Initial Sequence Number)


    确认号（32bit）：接收方对发送方TCP报文段的响应，其值是收到的序号值 + 1。

    首部长（4bit）：标识首部有多少个4字节 * 首部长，最大为15，即60字节。

    标志位（6bit）：

    URG：标志紧急指针是否有效。
    ACK：标志确认号是否有效（确认报文段）。用于解决丢包问题。
    PSH：提示接收端立即从缓冲读走数据。
    RST：表示要求对方重新建立连接（复位报文段）。
    SYN：表示请求建立一个连接（连接报文段）。
    FIN：表示关闭连接（断开报文段）。


    窗口（16bit）：接收窗口。用于告知对方（发送方）本方的缓冲还能接收多少字节数据。用于解决流控。


    校验和（16bit）：接收端用CRC检验整个报文段有无损坏。



## 常见TCP的连接状态
    CLOSED：初始状态。

    LISTEN：服务器处于监听状态。

    SYN_SEND：客户端socket执行CONNECT连接，发送SYN包，进入此状态。

    SYN_RECV：服务端收到SYN包并发送服务端SYN包，进入此状态。


    ESTABLISH：表示连接建立。客户端发送了最后一个ACK包后进入此状态，服务端接收到ACK包后进入此状态。

    FIN_WAIT_1：终止连接的一方（通常是客户机）发送了FIN报文后进入。等待对方FIN。
    
    CLOSE_WAIT：（假设服务器）接收到客户机FIN包之后等待关闭的阶段。在接收到对方的FIN包之后，自然是需要立即回复ACK包的，表示已经知道断开请求。但是本方是否立即断开连接（发送FIN包）取决于是否还有数据需要发送给客户端，若有，则在发送FIN包之前均为此状态。

    FIN_WAIT_2：此时是半连接状态，即有一方要求关闭连接，等待另一方关闭。客户端接收到服务器的ACK包，但并没有立即接收到服务端的FIN包，进入FIN_WAIT_2状态。
    
    LAST_ACK：服务端发动最后的FIN包，等待最后的客户端ACK响应，进入此状态。
    
    TIME_WAIT：客户端收到服务端的FIN包，并立即发出ACK包做最后的确认，在此之后的2MSL时间称为TIME_WAIT状态。


## 浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开

    1. 在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。所以虽然标准中没有设定，某些服务器对 Connection: keep-alive 的 Header 进行了支持。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免。

    2. 持久连接：既然维持 TCP 连接好处这么多，HTTP/1.1 就把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。

    3. 默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接。


## 三次握手

三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个
包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序
列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双
方的序列号和确认号，交换TCP窗口大小信息。


刚开始客户端处于 Closed 的状态，服务端处于 Listen 状态，进行三次握手：
1. 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN(c)。此时客户端
处于 SYN_SEND 状态。
首部的同步位SYN=1，初始序号seq=x，SYN=1的报文段不能携带数据，但要消耗掉一个序号。
2. 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了
自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端
的 SYN，此时服务器处于 SYN_RCVD 的状态。
在确认报文段中SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y。
3. 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 
1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 ESTABLISHED 状态。服务器
收到 ACK 报文之后，也处于 ESTABLISHED 状态，此时，双方已建立起了连接。
确认报文段ACK=1，确认号ack=y+1，序号seq=x+1（初始为seq=x，第二个报文段所以要+1），ACK
报文段可以携带数据，不携带数据则不消耗序号。
发送第一个SYN的一端将执行主动打开（active open），接收这个SYN并发回下一个SYN的另一端执行
被动打开（passive open）。
在socket编程中，客户端执行connect()时，将触发三次握手。


## 为什么需要三次握手，两次不行吗

1. 第一次握手：客户端发送网络包，服务端收到了。 这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
2. 第二次握手：服务端发包，客户端收到了。 这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
3. 第三次握手：客户端发包，服务端收到了。 这样服务端就能得出结论：客户端的接收、发送能力正
常，服务器自己的发送、接收能力也正常。


因此，需要三次握手才能确认双方的接收与发送能力是否正常

## 什么是半连接队列
服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。


当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象



## 三次握手过程中可以携带数据
其实第三次握手的时候，是可以携带数据的。但是，第一次、第二次握手不可以携带数据
为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务
器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接
收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来
接收这些报文。
也就是说，第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对
于第三次的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，
并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。


## SYN攻击
服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器
容易受到SYN洪泛攻击。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发
送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至
超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引
起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。


    在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击
    netstat -n -p TCP | grep SYN_RECV




##  四次挥手

建立一个连接需要三次握手，而终止一个连接要经过四次挥手（也有将四次挥手叫做四次握手的）。这
由TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送
后还能接收来自另一端数据的能力。
TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务器均可主动
发起挥手动作。


刚开始双方都处于 ESTABLISHED 状态，假如是客户端先发起关闭请求。四次挥手的过程如下：
1. 第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1 状
态。 即发出连接释放报文段（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入
FIN_WAIT1（终止等待1）状态，等待服务端的确认。
2. 第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的
序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT 状态。 即服务端收到连接释
放 报 文 段 后 即 发 出 确 认 报 文 段 （ ACK=1 ， 确 认 号 ack=u+1 ， 序 号 seq=v ） ， 服 务 端 进 入
CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端
收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。
3. 第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一
个序列号。此时服务端处于 LAST_ACK 的状态。 即服务端没有要向客户端发出的数据，服务端发出连
接释放报文段（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入LAST_ACK（最后确
认）状态，等待客户端的确认。
4. 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 
作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到
自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处
于 CLOSED 状态。 即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK=1，
seq=u+1，ack=w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时
间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。
收到一个FIN只意味着在这一方向上没有数据流动。客户端执行主动关闭并进入TIME_WAIT是正常
的，服务端通常执行被动关闭，不会进入TIME_WAIT状态。
5. 在socket编程中，任何一方执行close()操作即可产生挥手操作。

## 挥手为什么需要四次
因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来
应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭
SOCKET，所以只能先回复一个ACK报文，告诉客户端，"你发的FIN报文我收到了"。只有等到我服务
端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。




## 2MSL等待状态
TIME_WAIT状态也称为2MSL等待状态。每个具体TCP实现必须选择一个报文段最大生存时间
MSL（Maximum Segment Lifetime），它是任何报文段被丢弃前在网络内的最长时间。这个时间是有限
的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段。
对一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该
连接必须在TIME_WAIT状态停留的时间为2倍的MSL。这样可让TCP再次发送最后的ACK以防这个ACK
丢失（另一端超时并重发最后的FIN）。
这种2MSL等待的另一个结果是这个TCP连接在2MSL等待期间，定义这个连接的插口（客户的IP地址和
端口号，服务器的IP地址和端口号）不能再被使用。这个连接只能在2MSL结束后才能再被使用


## 四次挥手释放连接时，等待2MSL的意义

为了保证客户端发送的最后一个ACK报文段能够到达服务器。因为这个ACK有可能丢失，从而导致处在
LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端
再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待
2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭
连接状态。


两个理由
1. 保证客户端发送的最后一个ACK报文段能够到达服务端。 这个ACK报文段有可能丢失，使得处于
LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而
客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动
2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段
时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不
会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态。
2. 防止“已失效的连接请求报文段”出现在本连接中。 客户端在发送完最后一个ACK报文段后，再经过
2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不
会出现这种旧的连接请求报文段。


## TCP粘包问题是什么？你会如何去解决它
TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。


由TCP连接复用造成的粘包问题。
因为TCP默认会使用Nagle算法，此算法会导致粘包问题。
只有上一个分组得到确认，才会发送下一个分组；
收集多个小分组，在一个确认到来时一起发送。
数据包过大造成的粘包问题。
流量控制，拥塞控制也可能导致粘包。
接收方不及时接收缓冲区的包，造成多个包接收
解决：
1. Nagle算法问题导致的，需要结合应用场景适当关闭该算法
2. 尾部标记序列。通过特殊标识符表示数据包的边界，例如\n\r，\t，或者一些隐藏字符。
3. 头部标记分步接收。在TCP报文的头部加上表示数据长度。
4. 应用层发送数据时定长发送。


## 对称密钥加密的优点缺点
对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。
优点：运算速度快
缺点：无法安全地将密钥传输给通信方


## 非对称密钥加密你了解吗？优缺点
非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。
公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，
接收方收到通信内容后使用私有密钥解密。
非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使
用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正
确。
优点：可以更安全地将公开密钥传输给通信发送方；
缺点：运算速度慢。

## HTTPS是什么
1. HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通
信，也就是说 HTTPS 使用了隧道进行通信。通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防
伪装）和完整性保护（防篡改）。
2. HTTPS 采用混合的加密机制，使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使
用对称密钥加密进行通信来保证通信过程的效率。


## HTTP的缺点有哪些？
使用明文进行通信，内容可能会被窃听；
不验证通信方的身份，通信方的身份有可能遭遇伪装；
无法证明报文的完整性，报文有可能遭篡改。


## 为什么有的时候刷新页面不需要重新建立 SSL 连接？
TCP 连接有的时候会被浏览器和服务端维持一段时间，TCP 不需要重新建立，SSL 自然也会用之前的。

## 网络层常见协议
| 协议 | 名称 | 作用 |
| ------|---|---  | 
| IP | 网际协议 | IP协议不但定义了数据传输时的基本单元和格式，还定义了数据报的递交方法和路由选择
| ICMP | Internet控制报文协议 | ICMP就是一个“错误侦测与回报机制”，其目的就是让我们能够检测网路的连线状况﹐也能确保连线的准确性，是ping和traceroute的工作协议 |
| RIP | 路由信息协议 | 使用“跳数”(即metric)来衡量到达目标地址的路由距离 |
|IGMP | Internet组管理协议 | 用于实现组播、广播等通信 |


## TCP四大拥塞控制算法总结

1. 慢热启动算法 – Slow Start
所谓慢启动，也就是TCP连接刚建立，一点一点地提速，试探一下网络的承受能力，以免直接扰乱了
网络通道的秩序。
慢启动算法：
   1) 连接建好的开始先初始化拥塞窗口cwnd大小为1，表明可以传一个MSS大小的数据。
   2) 每当收到一个ACK，cwnd大小加一，呈线性上升。
   3) 每当过了一个往返延迟时间RTT(Round-Trip Time)，cwnd大小直接翻倍，乘以2，呈指数让升。
   4) 还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）

2. 拥塞避免算法 – Congestion Avoidance
如同前边说的，当拥塞窗口大小cwnd大于等于慢启动阈值ssthresh后，就进入拥塞避免算法。算法如
下：
   1) 收到一个ACK，则cwnd = cwnd + 1 / cwnd
   2) 每当过了一个往返延迟时间RTT，cwnd大小加一。过了慢启动阈值后，拥塞避免算法可以避免窗口增长过快导致窗口拥塞，而是缓慢的增加调整到网络的最佳值。

3. 拥塞发生状态时的算法
一般来说，TCP拥塞控制默认认为网络丢包是由于网络拥塞导致的，所以一般的TCP拥塞控制算法以
丢包为网络进入拥塞状态的信号。对于丢包有两种判定方式，一种是超时重传RTO[Retransmission 
Timeout]超时，另一个是收到三个重复确认ACK。
超时重传是TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个计时
器，在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止。
但是如果发送端接收到3个以上的重复ACK，TCP就意识到数据发生丢失，需要重传。这个机制不需
要等到重传定时器超时，所以叫
做快速重传，而快速重传后没有使用慢启动算法，而是拥塞避免算法，所以这又叫做快速恢复算法。
超时重传RTO[Retransmission Timeout]超时，TCP会重传数据包。TCP认为这种情况比较糟糕，反应也
比较强烈：
由于发生丢包，将慢启动阈值ssthresh设置为当前cwnd的一半，即ssthresh = cwnd / 2.
cwnd重置为1
进入慢启动过程
最为早期的TCP Tahoe算法就只使用上述处理办法，但是由于一丢包就一切重来，导致cwnd又重置为
1，十分不利于网络数据的稳定传递。
所以，TCP Reno算法进行了优化。当收到三个重复确认ACK时，TCP开启快速重传Fast Retransmit算
法，而不用等到RTO超时再进行重传：
cwnd大小缩小为当前的一半
ssthresh设置为缩小后的cwnd大小
然后进入快速恢复算法Fast Recovery。

4. 快速恢复算法 – Fast Recovery
 TCP Tahoe是早期的算法，所以没有快速恢复算法，而Reno算法有。在进入快速恢复之前，cwnd和
ssthresh已经被更改为原有cwnd的一半。快速恢复算法的逻辑如下：
cwnd = cwnd + 3 MSS，加3 MSS的原因是因为收到3个重复的ACK。
重传DACKs指定的数据包。
291
如果再收到DACKs，那么cwnd大小增加一。
如果收到新的ACK，表明重传的包成功了，那么退出快速恢复算法。将cwnd设置为ssthresh，然后进
入拥塞避免算法。


## 为何快速重传是选择3次ACK
主要的考虑还是要区分包的丢失是由于链路故障还是乱序等其他因素引发。
两次duplicated ACK时很可能是乱序造成的！三次duplicated ACK时很可能是丢包造成的！四次duplicated 
ACK更更更可能是丢包造成的，但是这样的响应策略太慢。丢包肯定会造成三次duplicated ACK!综上是
选择收到三个重复确认时窗口减半效果最好，这是实践经验。


在没有fast retransmit / recovery 算法之前，重传依靠发送方的retransmit timeout，就是在timeout内如果没
有接收到对方的ACK，默认包丢了，发送方就重传，包的丢失原因
    1）包checksum 出错
    2）网络拥塞
    3）网络断，包括路由重收敛，但是发送方无法判断是哪一种情况，于是采用最笨的办法，就是将自己
的发送速率减半，即CWND 减为1/2，这样的方法对2是有效的，可以缓解网络拥塞，3则无所谓，反正
网络断了，无论发快发慢都会被丢；但对于1来说，丢包是因为偶尔的出错引起，一丢包就对半减速不
合理。
于是有了fast retransmit 算法，基于在反向还可以接收到ACK，可以认为网络并没有断，否则也接收不到
ACK，如果在timeout 时间内没有接收到> 2 的duplicated ACK，则概率大事件为乱序，乱序无需重传，
接收方会进行排序工作；
而如果接收到三个或三个以上的duplicated ACK，则大概率是丢包，可以逻辑推理，发送方可以接收
ACK，则网络是通的，可能是1、2造成的，先不降速，重传一次，如果接收到正确的ACK，则一切
OK，流速依然（包出错被丢）。
而如果依然接收到duplicated ACK，则认为是网络拥塞造成的，此时降速则比较合理。

## 你了解流量控制原理吗
目的是接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致
接收方不能接收的问题。所以流量控制是点对点控制。


TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。
    发送窗：用来限制发送方可以发送的数据大小，其中发送窗口的大小由接收端返回的TCP报文段中窗口字段来控制，接收方通过此字段告知发送方自己的缓冲（受系统、硬件等限制）大小。
    接收窗：用来标记可以接收的数据大小。


TCP是流数据，发送出去的数据流可以被分为以下四部分：已发送且被确认部分 | 已发送未被确认部
分 | 未发送但可发送部分 | 不可发送部分，其中发送窗 = 已发送未确认部分 + 未发但可发送部分。接
收到的数据流可分为：已接收 | 未接收但准备接收 | 未接收不准备接收。接收窗 = 未接收但准备接收
部分。发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗，左边缘紧贴刚被确认
的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口。

## 83、建立TCP服务器的各个系统调用过程是怎样的   293


## TCP 协议如何保证可靠传输？
1. 确认和重传：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传。
2. 数据校验：TCP报文头有校验和，用于校验报文是否损坏。
数据合理分片和排序：tcp会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新
排序后交给应用层。而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分
片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组。由于
UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。
3. 流量控制：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止
包丢失。

4. 拥塞控制：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。



## 封包和拆包你听说过吗？它是基于TCP还是UDP的
封包和拆包都是基于TCP的概念。因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保
发送和接收的数据不粘连。
    封包：封包就是在发送数据报的时候为每个TCP数据包加上一个包头，将数据报分为包头和包体两个部分。包头是一个固定长度的结构体，里面包含该数据包的总长度。
    拆包：接收方在接收到报文后提取包头中的长度信息进行截取。

## TCP和UDP的区别
1. TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2. TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到
达;UDP尽最大努力交付，即不保证可靠交付
296
3. TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的
UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，
实时视频会议等）
4. 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信
5. TCP首部开销20字节;UDP的首部开销小，只有8个字节
6. TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道
7. UDP是面向报文的，发送方的UDP对应用层交下来的报文，不合并，不拆分，只是在其上面加上首
部后就交给了下面的网络层，论应用层交给UDP多长的报文，它统统发送，一次发送一个。而对接收
方，接到后直接去除首部，交给上面的应用层就完成任务了。因此，它需要应用层控制报文的大小
TCP是面向字节流的，它把上面应用层交下来的数据看成无结构的字节流会发送，可以想象成流水形式
的，发送方TCP会将数据放入“蓄水池”（缓存区），等到可以发送的时候就发送，不能发送就等着TCP
会根据当前网络的拥塞状态来确定每个报文段的大小




## UDP的特点有哪些（附赠TCP的特点）？
UDP是无连接的；
UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多
参数）；
UDP是面向报文的；
UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电
话，实时视频会议等）；
UDP支持一对一、一对多、多对一和多对多的交互通信；
UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。



TCP是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连
接）；
每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）；
TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设
有发送缓存和接收缓存，用来临时存放双方通信的数据；
面向字节流。TCP中的“流”（stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含
义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据
仅仅看成是一连串的无结构的字节流。


## 数据链路层

| 协议 | 名称 | 作用 |
| ------|---|---  | 
| ARP | 地址解析协议 | 根据IP地址获取物理地址 |
|RARP |反向地址转换协议 | 根据物理地址获取IP地址 |
|PPP 点对点协议 | 主要是用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种共通的解决方案 |

## 在进行UDP编程的时候，一次发送多少bytes好

鉴于Internet上的标准MTU值为576字节,所以我建议在进行Internet的UDP编程时.最好将UDP的数据长度控件在548字节(576-8-20)以内

## TCP 利用滑动窗口实现流量控制的机制
    流量控制是为了控制发送方发送速率，保证接收方来得及接收。TCP 利用滑动窗口实现流量控制。

    TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据。例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

## 可以解释一下RTO，RTT和超时重传分别是什么吗

超时重传：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：
发送的数据没能到达接收端，所以对方没有响应。
接收端接收到数据，但是ACK报文在返回过程中丢失。
接收端拒绝或丢弃数据。
    RTO：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间。就是重传间隔。通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTT......重传次数到达上限之后停止重传。
    
    RTT：数据从发送到接收到对方响应之间的时间间隔，即数据报在网络中一个往返用时。大小不稳定。

## XSS攻击是什么
跨站点脚本攻击，指攻击者通过篡改网页，嵌入恶意脚本程序，在用户浏览网页时，控制用户浏览器进
行恶意操作的一种攻击方式。如何防范XSS攻击
    1）前端，服务端，同时需要字符串输入的长度限制。
    2）前端，服务端，同时需要对HTML转义处理。将其中的”<”,”>”等特殊字符进行转义编码。防 XSS 的核心是必须对输入的数据做过滤处理。

## CSRF攻击
跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。可以这么理解CSRF攻
击：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。CRSF能做的事情包括利用你的身
份发邮件，发短信，进行交易转账，甚至盗取账号信息。

## 如何防范CSRF攻击
安全框架，例如Spring Security。
1. token机制。在HTTP请求中进行token验证，如果请求中没有token或者token内容不正确，则认为CSRF攻
击而拒绝该请求。
2. 验证码。通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证
码只能作为一种辅助手段，而不是最主要的解决方案。
3. referer识别。在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。如果Referer是其他
网站，就有可能是CSRF攻击，则拒绝该请求。但是，服务器并非都能取到Referer。很多用户出于隐私
保护的考虑，限制了Referer的发送。在某些情况下，浏览器也不会发送Referer，例如HTTPS跳转到
HTTP。 
    1）验证请求来源地址；
    2）关键操作添加验证码；
    3）在请求地址添加 token 并验证。

## 文件上传漏洞是如何发生的？你有经历过吗
文件上传漏洞，指的是用户上传一个可执行的脚本文件，并通过此脚本文件获得了执行服务端命令的能
力。
许多第三方框架、服务，都曾经被爆出文件上传漏洞，比如很早之前的Struts2，以及富文本编辑器等
等，可被攻击者上传恶意代码，有可能服务端就被人黑了。

## 如何防范文件上传漏洞
文件上传的目录设置为不可执行。
    1）判断文件类型。在判断文件类型的时候，可以结合使用MIME Type，后缀检查等方式。因为对于上
    传文件，不能简单地通过后缀名称来判断文件的类型，因为攻击者可以将可执行文件的后缀名称改为图
    片或其他后缀类型，诱导用户执行。
    2）对上传的文件类型进行白名单校验，只允许上传可靠类型。
    3）上传的文件需要进行重新命名，使攻击者无法猜想上传文件的访问路径，将极大地增加攻击成本，
    同时向shell.php.rar.ara这种文件，因为重命名而无法成功实施攻击。
    4）限制上传文件的大小。
    5）单独设置文件服务器的域名。


## 如何区分流量控制和拥塞控制
流量控制属于通信双方协商；拥塞控制涉及通信链路全局。流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。
实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。


## 服务器出现大量close_wait的连接的原因是什么？有什么解决方法？
close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因有两种：
1. 服务器内部业务处理占用了过多时间，都没能处理完业务；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法
2. 服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收


处理方法：
停止应用程序
修改程序里的bug


## 一台机器能够使用的端口号上限是多少，是否可以修改？如果想要用的端口超过这个限制怎么办
65536.因为TCP的报文头部中源端口号和目的端口号的长度是16位，也就是可以表示2^16=65536个不同
端口号，因此TCP可供识别的端口号最多只有65536个。但是由于0到1023是知名服务端口，所以实际上还要少1024个端口号。
而对于服务器来说，可以开的端口号与65536无关，其实是受限于Linux可以打开的文件数量，并且可以通过MaxUserPort来进行配置。





